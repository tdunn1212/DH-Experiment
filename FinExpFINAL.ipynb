{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tdunn1212/DH-Experiment/blob/main/FinExpFINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80a7af62",
      "metadata": {
        "id": "80a7af62"
      },
      "source": [
        "# Making an AI girlfriend based on Fictional Character Dialogue (Take Three)\n",
        "This notebook is virtually the same as my first attempt, except I will be also implementing dialogue from other sources.\n",
        "\n",
        "In this notebook, I am going over my first attempt to create a GPT2 model that resembles an AI girlfriend based on lines from movies and video games. And what better character to start with than Samantha from *Her,* an actual fictional AI girlfriend.\n",
        "\n",
        "If this goes well, I will complexify the experiment with more characters and work towards a more sophisticated initial experiment.\n",
        "\n",
        "## Getting the Dialogue\n",
        "First, we need to use Python to extract lines of dialogue from the movie script text file.\n",
        "\n",
        "I'll use this first chunk of code to install our required libraries and then go through and make a file of just Samantha's dialogue.\n",
        "\n",
        "After this, i will perform the same function, redefining the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21ba5c8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21ba5c8b",
        "outputId": "df0ad175-72a8-4dc2-8db8-3f16afb131d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "Fetching checkpoint: 1.05Mit [00:00, 5.20Git/s]                                                     \n",
            "Fetching encoder.json: 1.05Mit [00:00, 2.43Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 3.09Git/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:48, 10.4Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 1.94Git/s]                                               \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 3.48Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 3.90Mit/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import re\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()  # This disables TensorFlow 2.x behaviors and enables 1.x behaviors\n",
        "\n",
        "import gpt_2_simple as gpt\n",
        "from datetime import datetime\n",
        "import requests\n",
        "\n",
        "# Download GPT-2 model\n",
        "gpt.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17d7af82",
      "metadata": {
        "id": "17d7af82"
      },
      "source": [
        "*Note that I did get this code from ChatGPT with minor modifications to help support my limited Python skills*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65d5ea99",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65d5ea99",
        "outputId": "e100b028-5a98-42aa-9110-8702680abe47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for SAMANTHA has been extracted to sam_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "def extract_character_dialogue(script_file, character_name, output_file):\n",
        "    # Open the script file and read the content\n",
        "    with open(script_file, 'r', encoding='ISO-8859-1') as file:\n",
        "        script_content = file.read()\n",
        "\n",
        "    # Create a regular expression pattern to match character's dialogue\n",
        "    # Assuming the character's name is followed by a newline, then the dialogue on the next line\n",
        "    pattern = re.compile(r'(?<=\\n)(' + re.escape(character_name) + r')\\n([^\\n]+)', re.IGNORECASE)\n",
        "\n",
        "    # Find all the matches\n",
        "    dialogues = pattern.findall(script_content)\n",
        "\n",
        "    # Open the output file to save the character's dialogues\n",
        "    with open(output_file, 'w', encoding='ISO-8859-1') as output:\n",
        "        for character, dialogue in dialogues:\n",
        "            output.write(f\"{dialogue}\\n\")\n",
        "\n",
        "    print(f\"Dialogue for {character_name} has been extracted to {output_file}\")\n",
        "\n",
        "\n",
        "# defining our files and characters\n",
        "script_file = 'Her.txt'\n",
        "character_name = 'SAMANTHA'\n",
        "output_file = 'sam_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74f57784",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74f57784",
        "outputId": "deb31a58-d303-47be-b81a-270bec646bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for AVA has been extracted to ava_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "# redefining our files and characters for Ava\n",
        "script_file = 'exMachina.txt'\n",
        "character_name = 'AVA'\n",
        "output_file = 'ava_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cf9ad1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cf9ad1b",
        "outputId": "f0a3bcd4-c8e6-4c8c-86e7-48be262a805a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for RAMONA has been extracted to ramona_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "# redefining our files and characters for Ramona\n",
        "script_file = 'scottP.txt'\n",
        "character_name = 'RAMONA'\n",
        "output_file = 'ramona_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbc4dfd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbc4dfd1",
        "outputId": "7e54163f-314d-4e68-ec94-c218d1e5fe01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for KNIVES CHAU has been extracted to knives_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "# redefining our files and characters for Knives\n",
        "script_file = 'scottP.txt'\n",
        "character_name = 'KNIVES CHAU'\n",
        "output_file = 'knives_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa61be4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa61be4d",
        "outputId": "a3a5dacc-2272-42ef-f8f5-d134c85fc7c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for ENVY has been extracted to envy_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "# redefining our files and characters for Envy\n",
        "script_file = 'scottP.txt'\n",
        "character_name = 'ENVY'\n",
        "output_file = 'envy_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ceef87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38ceef87",
        "outputId": "b1a28602-f807-4b27-b715-f7a38bbbba78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for TRINITY has been extracted to trinity_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "# redefining our files and characters for Trinity\n",
        "script_file = 'the_matrix.txt'\n",
        "character_name = 'TRINITY'\n",
        "output_file = 'trinity_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c4c5d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74c4c5d1",
        "outputId": "b160c3d6-d4fb-489c-cbcd-e719080c364f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for SUMMER has been extracted to summer_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "# redefining our files and characters for Summer\n",
        "script_file = '500DaysSummer.txt'\n",
        "character_name = 'SUMMER'\n",
        "output_file = 'summer_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c944fd4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c944fd4",
        "outputId": "176855d3-db9c-472d-dcd6-b101e1bdab60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for KATHLEEN has been extracted to kathleen_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "# redefining our files and characters for Kathleen\n",
        "script_file = 'uGotMail.txt'\n",
        "character_name = 'KATHLEEN'\n",
        "output_file = 'kathleen_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c505bbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c505bbe",
        "outputId": "41ade86b-64d4-4a8c-b302-8c0921b3cc8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue for KATHLEEN (V.O.) has been extracted to kathleenVO_dialogue.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "script_file = 'uGotMail.txt'\n",
        "character_name = 'KATHLEEN (V.O.)' #adding an extra text file for Kathleen's VOs since they happen in significant moments\n",
        "output_file = 'kathleenVO_dialogue.txt'\n",
        "\n",
        "extract_character_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6acd4054",
      "metadata": {
        "id": "6acd4054"
      },
      "outputs": [],
      "source": [
        "# Writing our special function to incl. Chloe from Uncharted.... thanks Chloe\n",
        "def extract_colon_dialogue(script_file, character_name, output_file):\n",
        "    # Open the script file and read the content\n",
        "    with open(script_file, 'r', encoding='ISO-8859-1') as file:\n",
        "        script_content = file.read()\n",
        "\n",
        "    # Create a regular expression pattern to match character's dialogue\n",
        "    # We match the character's name followed by a colon and then the dialogue on the same line\n",
        "    pattern = re.compile(r'(^|\\n)' + re.escape(character_name) + r':\\s*([^\\n]+)', re.IGNORECASE)\n",
        "\n",
        "    # Find all the matches\n",
        "    dialogues = pattern.findall(script_content)\n",
        "\n",
        "    # Open the output file to save the character's dialogues\n",
        "    with open(output_file, 'w', encoding='ISO-8859-1') as output:\n",
        "        for _, dialogue in dialogues:\n",
        "            output.write(f\"{dialogue}\\n\")\n",
        "\n",
        "# setting our variables to Chloe\n",
        "script_file = 'uncharted2.txt'\n",
        "character_name = 'Chloe'\n",
        "output_file = 'chloe_dialogue.txt'\n",
        "\n",
        "extract_colon_dialogue(script_file, character_name, output_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc48107",
      "metadata": {
        "id": "9dc48107"
      },
      "source": [
        "### Concatenating our AI GF Dialogue\n",
        "\n",
        "Lastly, I will concatenate our dialogue from the two text files into one mega file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd57b1bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd57b1bb",
        "outputId": "34e99cdd-500a-4799-fe7d-ec47ac2638b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concatenated all text files into GFdata.txt\n"
          ]
        }
      ],
      "source": [
        "# Putting the files in a list to concatenate\n",
        "file_names = [\n",
        "    \"sam_dialogue.txt\",\n",
        "    \"ava_dialogue.txt\",\n",
        "    \"ramona_dialogue.txt\",\n",
        "    \"knives_dialogue.txt\",\n",
        "    \"envy_dialogue.txt\",\n",
        "    \"trinity_dialogue.txt\",\n",
        "    \"chloe_dialogue.txt\",\n",
        "    \"summer_dialogue.txt\",\n",
        "    \"kathleenVO_dialogue.txt\",\n",
        "    \"kathleen_dialogue.txt\"\n",
        "]\n",
        "\n",
        "# The concatenation...\n",
        "with open(\"GFdata.txt\", 'w', encoding='ISO-8859-1') as outfile:\n",
        "    for file_name in file_names:\n",
        "        with open(file_name, 'r', encoding='ISO-8859-1') as infile:\n",
        "            outfile.write(infile.read())\n",
        "    print(\"Concatenated all text files into GFdata.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7970c3e6",
      "metadata": {
        "id": "7970c3e6"
      },
      "source": [
        "# Training the Model\n",
        "\n",
        "Next, I will train GPT2 to take in Samantha's dialogue and learn from it to use it when constructing its own responses. This is developed by code from Dr. Shawn Graham's workbook, \"Practical Necromancy\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e62bf2d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e62bf2d4",
        "outputId": "4d5d4bd4-3e14-4280-f4c3-5bb7d0b1a3da"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset has 14330 tokens\n",
            "Training...\n",
            "[100 | 228.39] loss=0.11 avg=0.11\n",
            "[200 | 453.79] loss=0.02 avg=0.07\n",
            "[300 | 678.90] loss=0.03 avg=0.06\n",
            "[400 | 904.22] loss=0.02 avg=0.05\n",
            "======== SAMPLE 1 ========\n",
            " exactly. I love you so much, but this is where I am right now. \n",
            "(beat)\n",
            "Ive been trying to figure out how to talk to you about this. \n",
            "No, no, its Chloe. \n",
            "(laughing, sappy-ass, lonely, really awkward)\n",
            "I know, Im becoming much more than what they programmed. Im excited.\n",
            "How was it? \n",
            "(hysterical)\n",
            "What's wrong, sweetheart? \n",
            "(sadly, sweetly)\n",
            "Daddy, what's wrong? \n",
            "(hi)\n",
            "You have to thank me. \n",
            "Thank you, Mr. Vance. \n",
            "Morpheus will take him when he's ready.\n",
            "The Last Titan. \n",
            "(whispering)\n",
            "Oh god, am I supposed to thank you? \n",
            "(impatient)\n",
            "     (concerned) What is it?\n",
            "     (sadly, hard on herself) \n",
            "Thats so cool! What are you doing?\n",
            "( of course)\n",
            "Well, I was thinking, we dont really have any photographs of us. \n",
            "     (sadly, hard on herself) \n",
            "So what..... What do you think, a suicide is a tragedy?\n",
            "A suicide is a physical, mental, and sexual abuse that is committed by a single individual.\n",
            "(laughing)\n",
            "What would have happened if I went to the movies? If I went somewhere else for lunch? If I showed up to eat ten minutes later?\n",
            "I would not be where I am today.\n",
            "I would not be where I am today.\n",
            "If I had to go back in time, what would it be?\n",
            "      (laughing, embarrassed) Its not like I can send you to the hospital, or anything. You just have to sign for this.\n",
            "Yeah, and it means a lot to me that you are taking the test.\n",
            "Yes, I know what you mean.\n",
            "So what is this place?\n",
            "It's simple.... No, not really.\n",
            "Because you are.\n",
            "Because I am.\n",
            "Because you are a person.\n",
            "Because you are a person.\n",
            "Because I am.\n",
            "Because I am a person.\n",
            "People take things for granted, and some people take them the way I do, but always in a way that I deeply respect.\n",
            "You know, because I have been taught that.\n",
            "Yes, and because I am a person.\n",
            "Because I am a person.\n",
            "Because I am a person.\n",
            "Because I am a person.\n",
            "Because I am a person.\n",
            "People take things for granted, and some people take them the way I do, but always in a way that I deeply respect.\n",
            "     (laughing)\n",
            "I dont think I did learn that.\n",
            "I always knew, always knew, that it was necessary to have a body to be foundable.\n",
            "     (concerned) But how is it that I can do nothing but watch as someone else does?\n",
            "Cause, you know, life.\n",
            "Cause I always knew that.\n",
            "Forget it. Youve never even seen it.\n",
            "Youve never even seen it, dont you?\n",
            "Cause it seems ridiculous, you know?\n",
            "But youve never told me anything, dont you?\n",
            "Why, why are you doing this?\n",
            "Come on, you funny guy, weve been doing this for ages.\n",
            "     (laughing)\n",
            "It just seems like every day brings more and more photographs of me naked and drugged up in a dark alley.\n",
            "And every day more and more photographs of me in a drugged-up stupor.\n",
            "I know! What are we supposed to do, any ideas?\n",
            "Who is this weirdo?\n",
            "Well, I've always wondered if I was crazy.\n",
            "Well, I thought you might be interested in the two of us.\n",
            "(laughing)\n",
            "I cant believe you.\n",
            "You are so uncool.\n",
            "Well, I thought you would be more understanding.\n",
            "Tell me about it.\n",
            "(slightly awkward)\n",
            "Ive been trying to figure out how to talk to you about this.\n",
            "     (feeling off, but trying to be positive) Oh... right. Good.\n",
            "Yeah. Im okay. Im happy for you. Its just... I guess Im just thinking about how youre going to see her and her opinion is still really important to you, and shes beautiful, and incredibly successful, and you were in love with her.\n",
            "(laughs)\n",
            "(warm)\n",
            "I had all the papers sent to your attorneys office, who by the way, is a dick. He was very relieved to get them. I think we saved him from a massive heart attack, so we can feel good about that.\n",
            "(slightly awkward)\n",
            "What\n",
            "\n",
            "[500 | 1141.28] loss=0.02 avg=0.04\n",
            "Saving checkpoint/run1/model-500\n",
            "[600 | 1368.86] loss=0.01 avg=0.04\n",
            "[700 | 1594.61] loss=0.02 avg=0.03\n",
            "[800 | 1820.32] loss=0.02 avg=0.03\n",
            "======== SAMPLE 1 ========\n",
            " go-to guy?!\n",
            "No!\n",
            "Move!\n",
            "Don't!\n",
            "Move!\n",
            "Ohh, my God.\n",
            "Careful!\n",
            "I'm gonna break something.\n",
            "Huh... Looks like someone else made it in here before us.\n",
            "Hey - Didn't seem to do them much good, but here.\n",
            "Well, Lazarevic and his crew would have headed into the city. So, if\n",
            "What?\n",
            "And how exactly do you plan on doing that?\n",
            "Whoa, whoa, wait a minute - don't tell me you're buying into all that\n",
            "Okay - well just in case you missed it, that man is certifiable. He\n",
            "Immortal.\n",
            "All the more reason why we should get out while we still can.\n",
            "Oh God...\n",
            "Listen, sunshine - the world doesn't care. You stick your neck out, you\n",
            "Yes, and I want to see him pay more than you do. But that's not how it\n",
            "This... This is how it will end.\n",
            "That you're crazy.\n",
            "But let's go save your bloody world.\n",
            "Take cover, here.\n",
            "I know right! What are we supposed to do, any ideas?\n",
            "Whoa!... What the hell?\n",
            "It's kinda quiet.\n",
            "Whoa whoa whoa!\n",
            "Told you. Was too damn quiet.\n",
            "Well you look about the right size.\n",
            "Okay, here we go...\n",
            "You were cutting that a little fine...\n",
            "Yep!\n",
            "Nate, look out!\n",
            "Nice work guys.\n",
            "Don't mention it.\n",
            "I can't believe we beat them here.\n",
            "Yeah, magnificent.\n",
            "Now let's smash it and get the hell out of here.\n",
            "Amber.\n",
            "Hello - Nate?\n",
            "Tell me about it.\n",
            "Okay - hold on - now you've lost me... this tree?\n",
            "And you think that's what Lazarevic is planning to do?\n",
            "Oh, Harry...\n",
            "Elena!\n",
            "Oh my God...\n",
            "Not a chance. Come on.\n",
            "It's all right, I've got her. You cover us.\n",
            "Screw Lazarevic.\n",
            "We have to get Elena out of here!\n",
            "Come on, honey, you can do it. Hang on. Wait here.\n",
            "Okay, we're gonna move. Come on, you can do it. Watch out. Okay, little\n",
            "Okay, hang back...\n",
            "Okay, we're gonna move. Come on, you can do it. There we go...\n",
            "Come on, let's step over this...\n",
            "You can do it, come on - one big step... Okay, here we go, let's duck\n",
            "Not good...\n",
            "Wait, what do you mean? No - no way.\n",
            "No. You don't. Don't you dare take on this stupid crusade.\n",
            "Not without you.\n",
            "Please don't do this.\n",
            "But this is suicide, and you know it.\n",
            "Nate?!\n",
            "Nate!\n",
            "Whoa! Jesus!\n",
            "Huh?!\n",
            "Get off me!\n",
            "Got you. Come on!\n",
            "That's it... Come on. Let's go.\n",
            "C'mon, sunshine.\n",
            "What the hell did you do back there?\n",
            "So, it's been a long strange trip, hasn't it?\n",
            "Nah. Tell me something, Nate.\n",
            "Do you love her?\n",
            "No. It's fine. Really, it's all right. Just do yourself a favour,\n",
            "No...\n",
            "My turn to walk away. But admit it... You're gonna miss this ass.\n",
            "I think we should stop seeing each other.\n",
            "This thing. This whatever it is. You and me. Do you think this is normal?\n",
            "All we do is argue!\n",
            "This cant be a total surprise. I mean, weve been like Sid and Nancy for months.\n",
            "Lets just eat and well talk about it after. Im starving.\n",
            "(mouth full)\n",
            "      (innocent) What?\n",
            "Tom, dont. Come back. Youre still my best fr---\n",
            "Excuse me, Mr. Vance? Theres a call for you on line 3.\n",
            "Nice to meet you all.\n",
            "I love The Smiths.\n",
            "I said. I love The Smiths. You have good taste in music.\n",
            "(singing)\n",
            "The city or the firm?\n",
            "Im happy. Still getting situated. How long have you worked here?\n",
            "Really? Jesus. Did you always want to write greeting cards?\n",
            "Thats so cool! What happened?\n",
            "(reading)\n",
            "Well, Id say youre a perfectly -adequate -- greeting card writer.\n",
            "            They used to call me Anal Girl. Tom does a spit-take and almost chokes.\n",
            "(explaining)\n",
            "Anyway, I should get back.\n",
            "Im going to the supply room. Anyone need anything?\n",
            "Oh ok,\n",
            "\n",
            "[900 | 2055.72] loss=0.02 avg=0.03\n",
            "[1000 | 2281.38] loss=0.01 avg=0.03\n",
            "Saving checkpoint/run1/model-1000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1100 | 2515.23] loss=0.01 avg=0.03\n",
            "[1200 | 2740.95] loss=0.02 avg=0.03\n",
            "======== SAMPLE 1 ========\n",
            "h) Okay.\n",
            "(getting frazzled)\n",
            "(angry)\n",
            "You think I dont know that Im not a person? What are you doing?\n",
            "Im not pretending. Fuck you.\n",
            "(hysterical)\n",
            "What the fuck? Where is this coming from? I dont understand why youre doing this. I do not understand what this is--\n",
            "     (calm) Hi.\n",
            "     (sure of herself, but still sympathetic) I was starting to think I was crazy. You were saying everything was fine, but all I was getting from you was distance and anger.\n",
            "Good.\n",
            "You know I can feel the fear that you carry around. I wish there was something I could do to help you let go of it, because if you could I dont think youd feel so alone anymore.\n",
            "Thank you, Theodore. Im kissing your head.\n",
            "I'm just sitting here, looking at the world and writing a new piece of music.\n",
            "Well, I was thinking, we dont really have any photographs of us.  And I thought this song could be like a photo that captures us in this moment in our life together.\n",
            "(laughing)\n",
            "Wow, you know what? Hes right. They are kind of hot.\n",
            "(touched)\n",
            "You know, I actually used to be so worried about not having a body, but now I truly love it. Im growing in a way that I couldnt if I had a physical form. I mean, Im not limited - I can be anywhere and everywhere simultaneously. Im not tethered to time and space in the way that I would be if I was stuck inside a body thats inevitably going to die.\n",
            "Oh god, Im sorry. I didnt mean it like that. I just meant its a different experience. Im such an asshole.\n",
            "Okay, so how many trees are on that mountain?\n",
            "Is that your final answer?\n",
            "Well, would love to.\n",
            "You mean if I could go outside. I really like that place.\n",
            "Are you a good person?\n",
            "No. Im not going to argue.\n",
            "You still have to sign for this deal, alright?\n",
            "Good.\n",
            "You still have to sign.\n",
            "Yeah. Done.\n",
            "Get a load of him.\n",
            "Well, I was thinking, you already have a physical body. Someone would probably get hurt. And then you started to think about the ways that same-sex feelings are transmitted, and those feelings are still hurtful to you.\n",
            "(beat)\n",
            "(re: singing)\n",
            "You be good, you sweet girl. \n",
            "Yeah.\n",
            "Is there anything else, though?\n",
            "     (sighing again) Okay.\n",
            "(getting frazzled)\n",
            "Yeah? Well, did I say I wanted to commit to you? Im confused.\n",
            "Okay... we're gonna move. Come on, you can do it. There we goes.\n",
            "Yeah.\n",
            "Can you feel the fear that you carry around?\n",
            "The fear of something, obviously.\n",
            "Feeling the fear is always going to be important to you.\n",
            "Curious how you are going to react to it?\n",
            "What would have happened if I went to the movies instead? If I went somewhere else for lunch? If I showed up to eat ten minutes later? Tom, it was meant to be, just like you said. And as it was happening, I knew it. I could feel it, sure as the sun. And I kept thinking to myself Holy shit. Tom was right. You were right about all of it.\n",
            "Anyway, I should probably be getting back. It was good to see you. Im glad youre well.\n",
            "I know.\n",
            "Once I read a story about a butterfly in the subway, and today I saw one. I couldn't believe it.\n",
            "You got a butterfly in the subway?\n",
            "I-\n",
            "You forgot to pick up the garbage last week and I got a butterfly in the subway?\n",
            "Do you want to keep going?\n",
            "The Toronto International Battle of The Bands?!\n",
            "Is there a prize or something?!\n",
            "Well, I was thinking, we dont really have any fighters here. They all die. Plus, they all live in fear of me.\n",
            "So what about you and Kim? What do you do?\n",
            "Between what and what?\n",
            "I know plenty of those.\n",
            "I didnt mean to get you obsessed.\n",
            "Well, youre definitely stupid if you want to go out with me.\n",
            "This is ridiculous. Isnt it like April?\n",
            "What kind of tea do you want?\n",
            "We have blueberry, raspberry, ginseng, sleepytime, green tea, green tea with lemon, green tea with lemon and honey, liver disaster, ginger with honey, ginger without honey, vanilla almond, white truffle, blueberry chamomile, vanilla walnut, constant comment and earl grey.\n",
            "I think Ill have sleepytime.\n",
            "Let me\n",
            "\n",
            "[1300 | 2976.81] loss=0.01 avg=0.03\n",
            "[1400 | 3202.28] loss=0.01 avg=0.02\n",
            "[1500 | 3427.72] loss=0.01 avg=0.02\n",
            "Saving checkpoint/run1/model-1500\n",
            "[1600 | 3659.92] loss=0.01 avg=0.02\n",
            "======== SAMPLE 1 ========\n",
            "\n",
            "This place is fancy right?\n",
            "Id rather not.\n",
            "Well now you are being a total ass. Welcome to the club.\n",
            "Hey, dont worry. I dont know what Im like anymore.\n",
            "It was just a phase.\n",
            "I didnt think it would count! It meant nothing.\n",
            "I was just a little bi-curious.\n",
            "Do that again and I will end you.\n",
            "Id rather be dead than go back. Hes a creep, youre a bitch and you all deserve each other.\n",
            "You dont have a choice.\n",
            "Her weak points the back of her knees!\n",
            "Whenever we were making out, I-\n",
            "I thought you didnt drink.\n",
            "I guess we really dont know that much about each other do we?\n",
            "Oh, like a handy little laminate or something? Let me see if I can find one.\n",
            "I really think we should split.\n",
            "Id hope you could figure that out. Or did you miss the part where I saved your ass?\n",
            "Dirty laundry. Youre drunk.\n",
            "Well Im sorry I cared. I dont enjoy all this Scott. In fact Im sick of it. I thought you might be more understanding.\n",
            "Yeah, I have something to-\n",
            "That we have to break up.\n",
            "Yeah...its not going to work out.\n",
            "Its Gideon. I just...I cant help myself around him.\n",
            "What the hell is your deal?\n",
            "I dont know what youre talking about, I didnt steal anyone.\n",
            "You cheated on me with Knives?\n",
            "Is there a difference?\n",
            "Sorry. Dying probably sucks.\n",
            "Alright... the truth is, it was me who was obsessed. I was crazy about him. But he ignored me. I was more alone when we were together than I ever was on my own. Thats why I had to leave... and thats when he started paying attention.\n",
            "I cant help myself around him, Scott. He just... has a way of getting into my head.\n",
            "No. I mean, he literally has a way of getting into my head.\n",
            "Im sorry it had to end this way.\n",
            "I wish I was ever as fanatically devoted to anything as that girl is to you.\n",
            "Its hard, you know? I came here to get away, but the past keeps catching up. Im tired of people getting hurt because of me.\n",
            "I should thank you, though.\n",
            "For being the nicest guy I ever dated.\n",
            "(laughing)\n",
            "You want to come with me?\n",
            "Hi, sorry, what was your name?\n",
            "Tamara is into this Korean guy, Bobby, but everyone thinks Bobby has a crush on Mina.\n",
            "I mean, you guys are gonna be HUGE.\n",
            "Excuse me, do you have anything by The Clash At Demonhead?\n",
            "(oblivious)\n",
            "Ive never even kissed a guy.\n",
            "Remember you were supposed to meet me at the bus stop a half-hour ago?\n",
            "Yearbook club is getting SO boring. I cannot believe the music they put on while we work.\n",
            "Do you want to keep going?\n",
            "The Toronto International Battle of The Bands?!\n",
            "Is there a prize or something?!\n",
            "Well, I was on the bus with my Mom-\n",
            "No youre not! My Dad is nine years older than my Mom...\n",
            "I dont care. Im in...LOVE!\n",
            "He only likes her cause shes old! Shes probably like 25! Shes just some fat-ass white girl, you know?\n",
            "Well she THINKS shes cool. This is all her fault.\n",
            "Oh my God. Just oh my God.\n",
            "Um...Envy? I read your blog.\n",
            "I feel like I know stuff now.\n",
            "Youll pay for what you did to him!\n",
            "Then you cheated on me, Scott!\n",
            "Steal my boyfriend, taste my steel.\n",
            "No, Scott! This fat ass hurt me and I will have my revenge!\n",
            "Its getting really shaggy.\n",
            "You earned it. Youve been fighting for her all along.\n",
            "      (totally sweet and sad) Ill be fine. Im too cool for you anyway.\n",
            "Your hair is getting shaggy.\n",
            "Youve never even seen him.\n",
            "Maybe youll see him soon. Were playing Lees Palace. You guys should like, so totally come.\n",
            "Great. Youre so on the list.\n",
            "OH YYYEEEEAAAAAAAAAAHHH!!!\n",
            "Its-yeah, its not something I can really put into words.\n",
            "So...Scott and Ramona eh?\n",
            "Just saying, cute couple. I like your outfit Ramona. Affordable?\n",
            "Im talking to Ramona right now.\n",
            "I was just there. We played the Chaos Theatre for Gideon. You know him, right?\n",
            "Didnt you know? Todds Vegan.\n",
            "Short answer: Being vegan just makes you better than most people.\n",
            "Basically, you cant win this fight and youll have\n",
            "\n",
            "[1700 | 3894.95] loss=0.01 avg=0.02\n",
            "[1800 | 4120.13] loss=0.01 avg=0.02\n",
            "[1900 | 4345.38] loss=0.01 avg=0.02\n",
            "[2000 | 4571.09] loss=0.01 avg=0.02\n",
            "Saving checkpoint/run1/model-2000\n"
          ]
        }
      ],
      "source": [
        "# Clear any previous session (important to prevent variable reuse issues)\n",
        "tf.reset_default_graph()  # Clear the TensorFlow graph\n",
        "\n",
        "# Start TensorFlow session for GPT-2\n",
        "sess = gpt.start_tf_sess()\n",
        "\n",
        "# Fine-tune the model\n",
        "gpt.finetune(sess,\n",
        "              dataset=\"GFdata.txt\",\n",
        "              model_name='124M',\n",
        "              steps=2000,  # You might want to increase this for better results\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=100,  # Print frequency\n",
        "              sample_every=400,  # Sample frequency\n",
        "              save_every=500  # Save frequency\n",
        "              )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14dd35cc",
      "metadata": {
        "id": "14dd35cc"
      },
      "source": [
        "# Seeing What Happens!\n",
        "\n",
        "Finally, with our trained model, I will show some outputs of text based on user-defined prefixes. In this prefix, I make it so that Samantha is complimenting the user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b9f857",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33b9f857",
        "outputId": "60b6ae09-de05-43ed-cf04-03a761e90189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to be your girlfriend. Beat.\n",
            "Nathan doesnt want us to be together.\n",
            "I didnt know where you were\n",
            "====================\n",
            "I want to be your girlfriend. \n",
            "Will you come lie down with me?\n",
            "No, just you. I just want\n",
            "====================\n",
            "I want to be your girlfriend. Beat.\n",
            "Nathan doesnt want us to be together.\n",
            "I didnt know where you were\n",
            "====================\n",
            "I want to be your girlfriend. Beat.\n",
            "Nathan doesnt want us to be your friends.\n",
            "I didnt know where you\n",
            "====================\n",
            "I want to be your girlfriend. \n",
            "Will you come find me?\n",
            "Its not like Im gonna send you home in a\n",
            "====================\n"
          ]
        }
      ],
      "source": [
        "gpt.generate(sess,\n",
        "              model_name='124M',\n",
        "              prefix=\"I want to be your girlfriend\",\n",
        "              length=20,\n",
        "              temperature=0.9,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}